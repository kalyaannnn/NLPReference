{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMDOF+vX76C3QyZSfTGU+ge",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kalyaannnn/NLPReference/blob/main/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1IUpqAE2L53",
        "outputId": "dfbff719-c352-423e-ab39-b2bf83afa2b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.8/dist-packages (2.9.0)\n"
          ]
        }
      ],
      "source": [
        "pip install keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import imdb"
      ],
      "metadata": {
        "id": "ZDuOdVsd2zp6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 2500\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = vocab_size)\n",
        "print(\"Dataset with {} training samples and {} test samples\".format(len(X_train), len(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hH8KG_23J0M",
        "outputId": "0d8307b8-c26d-42e6-e849-c0fb8209575a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset with 25000 training samples and 25000 test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Review\")\n",
        "print(X_train[10])\n",
        "print(\"Label\")\n",
        "print(y_train[10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYHAahbL37Qm",
        "outputId": "7023bdcc-1ca1-4a59-eab4-8846d11692ec"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review\n",
            "[1, 785, 189, 438, 47, 110, 142, 7, 6, 2, 120, 4, 236, 378, 7, 153, 19, 87, 108, 141, 17, 1004, 5, 2, 883, 2, 23, 8, 4, 136, 2, 2, 4, 2, 43, 1076, 21, 1407, 419, 5, 2, 120, 91, 682, 189, 2, 5, 9, 1348, 31, 7, 4, 118, 785, 189, 108, 126, 93, 2, 16, 540, 324, 23, 6, 364, 352, 21, 14, 9, 93, 56, 18, 11, 230, 53, 771, 74, 31, 34, 4, 2, 7, 4, 22, 5, 14, 11, 471, 9, 2, 34, 4, 321, 487, 5, 116, 15, 2, 4, 22, 9, 6, 2286, 4, 114, 2, 23, 107, 293, 1008, 1172, 5, 328, 1236, 4, 1375, 109, 9, 6, 132, 773, 2, 1412, 8, 1172, 18, 2, 29, 9, 276, 11, 6, 2, 19, 289, 409, 4, 2, 2140, 2, 648, 1430, 2, 2, 5, 27, 2, 1432, 2, 103, 6, 346, 137, 11, 4, 2, 295, 36, 2, 725, 6, 2, 273, 11, 4, 1513, 15, 1367, 35, 154, 2, 103, 2, 173, 7, 12, 36, 515, 2, 94, 2, 1722, 5, 2, 36, 203, 30, 502, 8, 361, 12, 8, 989, 143, 4, 1172, 2, 10, 10, 328, 1236, 9, 6, 55, 221, 2, 5, 146, 165, 179, 770, 15, 50, 713, 53, 108, 448, 23, 12, 17, 225, 38, 76, 2, 18, 183, 8, 81, 19, 12, 45, 1257, 8, 135, 15, 2, 166, 4, 118, 7, 45, 2, 17, 466, 45, 2, 4, 22, 115, 165, 764, 2, 5, 1030, 8, 2, 73, 469, 167, 2127, 2, 1568, 6, 87, 841, 18, 4, 22, 4, 192, 15, 91, 7, 12, 304, 273, 1004, 4, 1375, 1172, 2, 2, 15, 4, 22, 764, 55, 2, 5, 14, 2, 2, 4, 1375, 326, 7, 4, 2, 1786, 8, 361, 1236, 8, 989, 46, 7, 4, 2, 45, 55, 776, 8, 79, 496, 98, 45, 400, 301, 15, 4, 1859, 9, 4, 155, 15, 66, 2, 84, 5, 14, 22, 1534, 15, 17, 4, 167, 2, 15, 75, 70, 115, 66, 30, 252, 7, 618, 51, 9, 2161, 4, 2, 5, 14, 1525, 8, 2, 15, 2, 165, 127, 1921, 8, 30, 179, 2, 4, 22, 9, 906, 18, 6, 176, 7, 1007, 1005, 4, 1375, 114, 4, 105, 26, 32, 55, 221, 11, 68, 205, 96, 5, 4, 192, 15, 4, 274, 410, 220, 304, 23, 94, 205, 109, 9, 55, 73, 224, 259, 2, 15, 4, 22, 528, 1645, 34, 4, 130, 528, 30, 685, 345, 17, 4, 277, 199, 166, 281, 5, 1030, 8, 30, 179, 2, 444, 2, 9, 6, 371, 87, 189, 22, 5, 31, 7, 4, 118, 7, 4, 2068, 545, 1178, 829]\n",
            "Label\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2ID = imdb.get_word_index()\n",
        "id2word = {i :word for word, i in word2ID.items()}\n",
        "print(\"Review in words\")\n",
        "print([id2word.get(i, '') for i in X_train[10]])\n",
        "print(\"Label\")\n",
        "print(y_train[10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8RQ8lqK4m5L",
        "outputId": "438def2a-25a3-4d1a-8aaa-5d2d13b616b9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review in words\n",
            "['the', 'clear', 'fact', 'entertaining', 'there', 'life', 'back', 'br', 'is', 'and', 'show', 'of', 'performance', 'stars', 'br', 'actors', 'film', 'him', 'many', 'should', 'movie', 'reasons', 'to', 'and', 'reading', 'and', 'are', 'in', 'of', 'scenes', 'and', 'and', 'of', 'and', 'out', 'compared', 'not', 'boss', 'yes', 'to', 'and', 'show', 'its', 'disappointed', 'fact', 'and', 'to', 'it', 'justice', 'by', 'br', 'of', 'where', 'clear', 'fact', 'many', 'your', 'way', 'and', 'with', 'city', 'nice', 'are', 'is', 'along', 'wrong', 'not', 'as', 'it', 'way', 'she', 'but', 'this', 'anything', 'up', \"haven't\", 'been', 'by', 'who', 'of', 'and', 'br', 'of', 'you', 'to', 'as', 'this', \"i'd\", 'it', 'and', 'who', 'of', 'shot', \"you'll\", 'to', 'love', 'for', 'and', 'of', 'you', 'it', 'is', 'sequels', 'of', 'little', 'and', 'are', 'seen', 'watched', 'front', 'chemistry', 'to', 'simply', 'alive', 'of', 'chris', 'being', 'it', 'is', 'say', 'easy', 'and', 'cry', 'in', 'chemistry', 'but', 'and', 'all', 'it', 'maybe', 'this', 'is', 'and', 'film', 'job', 'live', 'of', 'and', 'relief', 'and', 'level', 'names', 'and', 'and', 'to', 'be', 'and', 'serial', 'and', 'watch', 'is', 'men', 'go', 'this', 'of', 'and', 'american', 'from', 'and', 'moving', 'is', 'and', 'put', 'this', 'of', 'jerry', 'for', 'places', 'so', 'work', 'and', 'watch', 'and', 'lot', 'br', 'that', 'from', 'sometimes', 'and', 'make', 'and', 'introduced', 'to', 'and', 'from', 'action', 'at', 'turns', 'in', 'low', 'that', 'in', 'gay', \"i'm\", 'of', 'chemistry', 'and', 'i', 'i', 'simply', 'alive', 'it', 'is', 'time', 'done', 'and', 'to', 'watching', 'look', 'world', 'named', 'for', 'more', 'tells', 'up', 'many', 'fans', 'are', 'that', 'movie', 'music', 'her', 'get', 'and', 'but', 'seems', 'in', 'people', 'film', 'that', 'if', 'explain', 'in', 'why', 'for', 'and', 'find', 'of', 'where', 'br', 'if', 'and', 'movie', 'throughout', 'if', 'and', 'of', 'you', 'best', 'look', 'red', 'and', 'to', 'recently', 'in', 'and', 'much', 'unfortunately', 'going', 'dan', 'and', 'stuck', 'is', 'him', 'sequences', 'but', 'of', 'you', 'of', 'enough', 'for', 'its', 'br', 'that', 'beautiful', 'put', 'reasons', 'of', 'chris', 'chemistry', 'and', 'and', 'for', 'of', 'you', 'red', 'time', 'and', 'to', 'as', 'and', 'and', 'of', 'chris', 'less', 'br', 'of', 'and', 'torture', 'in', 'low', 'alive', 'in', 'gay', 'some', 'br', 'of', 'and', 'if', 'time', 'actual', 'in', 'also', 'side', 'any', 'if', 'name', 'takes', 'for', 'of', 'friendship', 'it', 'of', '10', 'for', 'had', 'and', 'great', 'to', 'as', 'you', 'students', 'for', 'movie', 'of', 'going', 'and', 'for', 'bad', 'well', 'best', 'had', 'at', 'woman', 'br', 'musical', 'when', 'it', 'caused', 'of', 'and', 'to', 'as', 'gem', 'in', 'and', 'for', 'and', 'look', 'end', 'gene', 'in', 'at', 'world', 'and', 'of', 'you', 'it', 'meet', 'but', 'is', 'quite', 'br', 'western', 'ideas', 'of', 'chris', 'little', 'of', 'films', 'he', 'an', 'time', 'done', 'this', 'were', 'right', 'too', 'to', 'of', 'enough', 'for', 'of', 'ending', 'become', 'family', 'beautiful', 'are', 'make', 'right', 'being', 'it', 'time', 'much', 'bit', 'especially', 'and', 'for', 'of', 'you', 'parts', 'bond', 'who', 'of', 'here', 'parts', 'at', 'due', 'given', 'movie', 'of', 'once', 'give', 'find', 'actor', 'to', 'recently', 'in', 'at', 'world', 'and', 'loved', 'and', 'it', 'is', 'video', 'him', 'fact', 'you', 'to', 'by', 'br', 'of', 'where', 'br', 'of', 'grown', 'fight', 'culture', 'leads']\n",
            "Label\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "max_size = 250\n",
        "\n",
        "X_test = pad_sequences(X_test, maxlen= max_size)\n",
        "X_train = pad_sequences(X_train, maxlen = max_size)"
      ],
      "metadata": {
        "id": "aQ0NiQq45eVm"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import LSTM\n",
        "\n",
        "embedding_size = 32\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_size, input_length = max_size))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wA_V1B6s9aZF",
        "outputId": "238f46dd-0a86-44ca-8087-352fd6365dd2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 250, 32)           80000     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 100)               53200     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 133,301\n",
            "Trainable params: 133,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9BWmhNq-Q3u",
        "outputId": "56827b74-3aca-42c8-bb3d-60dccce11c33"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 250, 32)           80000     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 100)               53200     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 133,301\n",
            "Trainable params: 133,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "n_epochs = 3\n",
        "\n",
        "X_valid, y_valid = X_train[: batch_size], y_train[: batch_size]\n",
        "X_train2, y_train2 = X_train[batch_size :], y_train[batch_size :]\n",
        "\n",
        "model.fit(X_train2, y_train2, validation_data = (X_valid, y_valid), batch_size = batch_size, epochs = n_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRaq2EEJ__g1",
        "outputId": "5dd3f8d5-faad-422b-9d71-3490acd16491"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "390/390 [==============================] - 80s 199ms/step - loss: 0.4588 - accuracy: 0.7789 - val_loss: 0.2810 - val_accuracy: 0.8750\n",
            "Epoch 2/3\n",
            "390/390 [==============================] - 79s 202ms/step - loss: 0.3128 - accuracy: 0.8721 - val_loss: 0.3183 - val_accuracy: 0.8750\n",
            "Epoch 3/3\n",
            "390/390 [==============================] - 77s 199ms/step - loss: 0.2758 - accuracy: 0.8889 - val_loss: 0.2372 - val_accuracy: 0.9219\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2a029ee100>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    }
  ]
}